"""
Enhanced Prediction Service - combines HuggingFace model + DeepSeek classifier + DeepSeek explainer.
"""
from typing import Dict, Optional
from datetime import datetime

from app.services.fake_news_service import fake_news_detector
from app.services.deepseek_service import deepseek_service
from app.core.logger import get_logger

logger = get_logger(__name__)


class EnhancedPredictionService:
    """
    Composite service to analyse fake news with the full workflow:
    1. HuggingFace model (local or API)
    2. DeepSeek classifier
    3. DeepSeek explainer (analysis and warnings)
    """
    
    def __init__(self):
        """Kh·ªüi t·∫°o service."""
        self.hf_service = fake_news_detector
        self.generation_service = deepseek_service
    
    def _prepare_text_from_post(self, post: Dict) -> str:
        """
        Chu·∫©n b·ªã text t·ª´ post ƒë·ªÉ ph√¢n t√≠ch.
        
        Args:
            post: Dict ch·ª©a th√¥ng tin post (title, selftext, ...)
            
        Returns:
            Text ƒë√£ ƒë∆∞·ª£c chu·∫©n b·ªã
        """
        title = post.get("title", "")
        selftext = post.get("selftext", "")
        
        # ∆Øu ti√™n title, th√™m selftext n·∫øu c√≥
        if selftext and len(selftext) > 20:
            text = f"{title}. {selftext}"
        else:
            text = title
        
        # Gi·ªõi h·∫°n ƒë·ªô d√†i
        max_length = 512
        if len(text) > max_length:
            logger.debug(f"Text d√†i {len(text)} k√Ω t·ª±, c·∫Øt xu·ªëng {max_length}")
            text = text[:max_length]
        
        return text
    
    async def analyze_news(self, text: str) -> Dict:
        """
        Run the full enhanced workflow on raw news text.

        Returns a dict:
            {
                "hf": {...},                    # HuggingFace result
                "gemini_classifier": {...},     # DeepSeek classifier result (key kept for backwards-compat)
                "analysis": str,                # Explanation and warning text
                "analyzed_at": str,             # Timestamp
                "workflow_version": str
            }
        """
        logger.info("üîç Starting enhanced analysis workflow...")
        
        # Step 1: HuggingFace prediction
        logger.debug("Step 1/3: Running HuggingFace model...")
        hf_result = await self.hf_service.predict_text(text)
        
        if not hf_result:
            logger.warning("‚ö†Ô∏è  HuggingFace prediction failed, returning default result")
            hf_result = {
                "label": "UNKNOWN",
                "confidence": 0.0,
                "scores": {"fake": 0.0, "real": 0.0},
                "predicted_at": datetime.now().isoformat(),
                "model": self.hf_service.model_name,
                "error": "Prediction failed"
            }
        
        # Step 2: Classify with DeepSeek
        logger.debug("Step 2/3: Running DeepSeek classifier...")
        logger.debug(f"üìù Text sent to DeepSeek (length: {len(text)}): {text[:200]}...")
        
        gemini_quota_exceeded = False
        try:
            gemini_classifier_result = self.generation_service.classify_fake_news(text)
            logger.debug(f"‚úÖ DeepSeek classifier result: {gemini_classifier_result}")
            
            # Check for quota-like errors encoded in result
            if (gemini_classifier_result.get("label") == "uncertain" and 
                gemini_classifier_result.get("confidence", 0.0) == 0.0 and
                "quota" in gemini_classifier_result.get("reason", "").lower()):
                gemini_quota_exceeded = True
                logger.warning("‚ö†Ô∏è  Detected DeepSeek quota exceeded from classifier result")
                
        except Exception as e:
            logger.error(f"‚ùå Error when calling DeepSeek classifier: {e}", exc_info=True)
            # Check if this looks like a quota error
            error_str = str(e).lower()
            if "429" in str(e) or "quota" in error_str:
                gemini_quota_exceeded = True
                logger.warning("‚ö†Ô∏è  DeepSeek quota exceeded - skipping explanation step")
            
            # Default classifier result on error
            gemini_classifier_result = {
                "label": "uncertain",
                "confidence": 0.0,
                "reason": f"Error calling DeepSeek: {str(e)[:100]}",
                "model": self.generation_service.model_name,
                "classified_at": datetime.now().isoformat()
            }
        
        # Step 3: Explanation and warnings (skip if quota exceeded)
        if gemini_quota_exceeded:
            logger.warning("‚è≠Ô∏è  Skipping DeepSeek explanation due to quota exceeded")
            analysis = (
                "‚ö†Ô∏è **Note:** DeepSeek API appears to have hit a quota or rate limit.\n\n"
                "**HuggingFace model result:**\n"
                f"- Label: **{hf_result.get('label', 'UNKNOWN')}**\n"
                f"- Confidence: **{hf_result.get('confidence', 0.0):.1%}**\n\n"
                "*This result is based only on the HuggingFace model. For a full DeepSeek explanation, "
                "please retry later or increase your plan limits.*"
            )
        else:
            logger.debug("Step 3/3: Generating explanation and warnings with DeepSeek...")
            analysis = self.generation_service.explain_and_warn(
                text,
                hf_result,
                gemini_classifier_result
            )
        
        result = {
            "hf": hf_result,
            "gemini_classifier": gemini_classifier_result,
            "analysis": analysis,
            "analyzed_at": datetime.now().isoformat(),
            "workflow_version": "2.0"  # Enhanced workflow using DeepSeek
        }
        
        logger.info("‚úÖ Enhanced analysis workflow completed")
        
        return result
    
    async def analyze_post(self, post: Dict) -> Optional[Dict]:
        """
        Ph√¢n t√≠ch m·ªôt Reddit post v·ªõi workflow ƒë·∫ßy ƒë·ªß.
        
        Args:
            post: Dict ch·ª©a th√¥ng tin post (title, selftext, post_id, ...)
            
        Returns:
            Dict v·ªõi k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß ho·∫∑c None n·∫øu th·∫•t b·∫°i
        """
        post_id = post.get("post_id", "unknown")
        logger.info(f"üîç Ph√¢n t√≠ch post: {post_id}")
        
        try:
            # Chu·∫©n b·ªã text
            text = self._prepare_text_from_post(post)
            
            if not text or len(text.strip()) < 10:
                logger.warning(f"‚ö†Ô∏è  Post {post_id} c√≥ text qu√° ng·∫Øn ƒë·ªÉ ph√¢n t√≠ch")
                return None
            
            # Ph√¢n t√≠ch v·ªõi workflow ƒë·∫ßy ƒë·ªß
            result = await self.analyze_news(text)
            
            # Th√™m metadata
            result["post_id"] = post_id
            result["title"] = post.get("title", "")
            
            logger.info(
                f"‚úÖ Ph√¢n t√≠ch ho√†n t·∫•t cho post {post_id}: "
                f"HF={result['hf'].get('label')}, "
                f"Gemini={result['gemini_classifier'].get('label')}"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi ph√¢n t√≠ch post {post_id}: {e}")
            return None
    
    def _get_summary_label(self, result: Dict) -> str:
        """
        T·∫°o label t·ªïng h·ª£p t·ª´ c·∫£ 2 model.
        
        Args:
            result: K·∫øt qu·∫£ t·ª´ analyze_news()
            
        Returns:
            Label t·ªïng h·ª£p: "FAKE", "REAL", ho·∫∑c "UNCERTAIN"
        """
        hf_label = result.get("hf", {}).get("label", "UNKNOWN").upper()
        gemini_label = result.get("gemini_classifier", {}).get("label", "unknown").upper()
        
        # N·∫øu c·∫£ 2 ƒë·ªÅu ƒë·ªìng thu·∫≠n
        if hf_label == gemini_label and hf_label in ["FAKE", "REAL"]:
            return hf_label
        
        # N·∫øu m√¢u thu·∫´n
        if hf_label in ["FAKE", "REAL"] and gemini_label in ["FAKE", "REAL"]:
            if hf_label != gemini_label:
                return "UNCERTAIN"
        
        # N·∫øu m·ªôt trong hai l√† uncertain
        if "UNCERTAIN" in [hf_label, gemini_label]:
            other = hf_label if gemini_label == "UNCERTAIN" else gemini_label
            if other in ["FAKE", "REAL"]:
                return other
        
        return "UNCERTAIN"
    
    def format_for_database(self, result: Dict) -> Dict:
        """
        Format k·∫øt qu·∫£ ƒë·ªÉ l∆∞u v√†o database.
        
        Args:
            result: K·∫øt qu·∫£ t·ª´ analyze_news() ho·∫∑c analyze_post()
            
        Returns:
            Dict ƒë∆∞·ª£c format ƒë·ªÉ l∆∞u v√†o DB
        """
        summary_label = self._get_summary_label(result)
        
        return {
            "label": summary_label,
            "confidence": result.get("hf", {}).get("confidence", 0.0),
            "hf": result.get("hf"),
            "gemini_classifier": result.get("gemini_classifier"),
            "analysis": result.get("analysis"),
            "analyzed_at": result.get("analyzed_at"),
            "workflow_version": result.get("workflow_version", "2.0")
        }


# Global instance
enhanced_prediction_service = EnhancedPredictionService()

